{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework\n",
    "\n",
    "Greetings. This homework will help you get some familiarity with how machine (deep) learning and neural networks are used in practice. Don't worry if you don't have any coding experience, you just have to make small modifications and copy+paste with helpful hints.\n",
    "\n",
    "Try to keep the worksheet organized as you will have to submit it at the end. **In addition**, you will need to answer specific numerical/multiple choice questions on **bCourses** so that grading becomes easier. Most of the time there is no single correct answer, it just helps us going through your work faster. You are also free to add comments to this worksheet if you want to clarify/explain what you did, but it's not required.\n",
    "\n",
    "Some *hints* for how to use this worksheet:\n",
    "* To _execute_ the code in a cell, press *Ctrl+Enter* or use the little 'Run' icon above\n",
    "* Sometimes there is no output even if execution is successful, so don't be surprised. If you see In[*] the command is running, if you see In[x], where x is a number it's done. The very first cell block you run might take a while.\n",
    "* _Be careful_ with the order of executing. If you go in order, nothing unexpected will happen, but if you jump around and execute cell out of order, it might mess things up. If you want to start with a clean slate, go to Kernel -> Restart & Clear Output\n",
    "* If you leave your workbook and come back later, the python kernel may stop in the meanwhile and it will \"forget\" everything it has already computed. So you need to rerun all the cells from the beginning. If in doubt, just  go to Kernel -> Restart & Clear Output and rerun each cell.\n",
    "* To _insert_ a cell use the plus icon or Insert in the menu\n",
    "* Most of the code (the important parts) are fairly simple. The longer/complicated parts are for plotting. So don't worry if you can't follow those\n",
    "* Although you are not required to, you can add comments if you want to. There are two ways\n",
    "  * In a code cell block, start a line with # character\n",
    "  * You can add a cell block and change it to *Markdown* from *Code* in the dropdown next to the control icons. In a markdown cell, you can just put text and when you hit *Ctrl+Enter* it will format it as text.\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Let's get started. The following code will just import some libraries. The most important ones are tensorflow and keras. These are the main neural network libraries. The others are useful utilities mostly for plotting and some math/stats shortcuts.\n",
    "\n",
    "Go ahead and execute the cell below. If you see the version of Tensorflow as a result, all is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import itertools\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#This is just an example comment\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect Data\n",
    "\n",
    "Let's load the data. This is a nice clean dataset used in many tutorials. You can find more info [here](https://www.kaggle.com/zalando-research/fashionmnist). \n",
    "\n",
    "The first line points to the data, the second line loads the data. There are four parts to it. It's divided to _train_ and _test_. Within each there are the images and the labels, hence 2x2=4 objects. The third line will display the shape of the training image object. It  should show you (60000,28,28) because there are 60,000 images and each image consist of 28x28 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = fashion_mnist.load_data()\n",
    "mnist_train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ok, here is the first task. Create a cell below and try to figure out how many images are in the test set.\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 1:__</span> How many images are in the test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Take a look at the first image. Programmers always start indexing at 0 so that's why you have `mnist_train_images[0]` in the code. Each pixel is a number between 0 and 255 representing light or dark (note the images are not colored, we are just showing the pixel intensity with colors here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mnist_train_images[0],cmap='YlOrRd')\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the label of this image is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Well, it's 9. Looks like a boot, but we got a number. The reason is that the data we loaded **does not** contain the text labels, just a number for each category. Therefore, we need to manually specify the textual labels in the following code cell. (Note that when you execute the cell, it will not display any output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with the class names defined, we can easily display the label for the first training image (indexed as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[mnist_train_labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Ok, now you try. Insert a code cell to display the second training image (just copy and modify the previous code displaying the first image).\n",
    "### <span style=\"color:red\">__bCourses Question 2:__</span> Upload the second training image (as an image to bCourses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now let's see the label. Create a code cell block to display the label of the second training image.\n",
    "### <span style=\"color:red\">__bCourses Question 3:__</span> What is the label of the second training image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "How about the third one? \n",
    "### <span style=\"color:red\">__bCourses Question 4:__</span> What is the label of the third training image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "Cleaning/preprocessing data is usually a gigantic task. This data set that we are using is already very clean and nice, so we just need to complete some very simple steps.\n",
    "\n",
    "The first one is to normalize the images so that the intensity of a pixel is measured between 0 and 1 and not 0 and 255. (This is not strictly necessary for things to work, but often helps and makes the training faster. Often data is normalized to [-1,1] instead of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_images = mnist_train_images / 255.0\n",
    "mnist_test_images = mnist_test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "If you executed the block above, it will not give an output, but let's see if it worked. Let's plot the first image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(mnist_train_images[0],cmap='YlOrRd')\n",
    "plt.colorbar()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good. Maximum intensity is now 1.0. Now let's take a look a few more training images (the first 49). Don't worry about the code, it just creates a nice grid of images. Just pay attention to the _last two lines_ where we tell it to display the labels from the `mnist_train_labels` array and the images from the `mnist_train_images` array. The `[i]` means that we want to display the label/image with index `i`, where `i` goes from 0 to 48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(0,49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title(class_names[mnist_train_labels[i]])\n",
    "    plt.imshow(mnist_train_images[i], cmap='Blues')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same thing for the **test** images. We want to make sure that those look reasonable as well. Create a code cell block to display the first 49 **test** images. *Hint: Copy and modify the code from above and replace the references to the training data with references to the test data in the last two lines (also change 'Blues' to 'Oranges' to make it even nicer)*\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 5:__</span> Upload the test image grid to bCourses\n",
    "### <span style=\"color:red\">__bCourses Question 6:__</span> What is the label of the first test image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last step before we get to neural networks. Remember, how we want to have more than just training and test data. We want to experiment with different models, so we want to split the training data further and save some of it for validation. That is what the following line of code does. The first line splits the mnist training data into two parts. 80% of it we will actually use for training and 20% for validation. The second line just displays the size of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_train_images, our_val_images, our_train_labels, our_val_labels = train_test_split(mnist_train_images, mnist_train_labels, test_size=12000)\n",
    "our_val_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A simple question: what is the size of the set that we will actually use for training (our training data)? You can use code or just calculate it manually.\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 7:__</span> How many images are in our new training data set, that we will actually use for training? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Setup\n",
    "Finally! We are ready to set up a neural network. This is where the *keras* library is really useful. It let's you set up a neural network model in just a few steps. \n",
    "\n",
    "* The first line below creates an empty network and you add layers one by one. Our first network is super simple. It has two layers: an input layer and an output layer, no hidden layers! \n",
    "* The input layer defined in the second line is simply a 28x28=784 dimensional vector, where each dimension corresponds to a pixel in the input image. (The reason the code has the `Flatten` function is because our images are stored as 2D object and this just \"flattens\" them into a vector). \n",
    "* The output layer given in the third line is just 10 nodes, where each node corresponds to one of the categories. The activation levels of these output nodes will give us the prediction. The highest activation is the predicted category. (The 'softmax' activation makes sure that the activations in this layer add up to 1 so the activations are very easy to interpret as a probability of being in the class). This layer is 'dense' because all nodes in the output layer are connected to all nodes in the input layer. \n",
    "* The fourth line compiles the model, here is where we specify the loss function, what \"optimizer\" to use and what metrics to display. You have to do this before training.\n",
    "* The last line prints a summary of the model (this what provides the output when you run the block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential()\n",
    "model1.add (keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model1.add (keras.layers.Dense(10,activation='softmax'))\n",
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Setup\n",
    "\n",
    "Now it's time for training the model. This is the most time consuming part. For this simple network it will be fast, but for more complex ones it can take a while. All you have to specify is the training data (input and output - in our case images and labels and how long it should run. This is what's called epoch. One epoch goes through all the training data once. But you might need to train longer. As long as accuracy improves, it might make sense to run longer. 5 epochs is going to be more than enough for this simple one. *(Note that in the beginning the network is initialized with random weights, so accuracy will start out around 10%, totally random. And it will improve as you train longer. Also note that if you rerun the block by hitting Ctrl+Enter again it will not restart at random, but continue from where it was. So if you have epoch=5 set and run it twice, that's equivalent to epoch=10. But for readability of this notebook try to run only once and set a higher epoch in the final version)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(our_train_images, our_train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "Now you already see accuracy levels in the output above. Accuracy is simply the percentage of images that are correctly predicted by the model. But those are the accuracy levels in the **training** data. You need to check the performance in the **validation** data. So below, we *evaluate* the model on the validation data (first line) and display the accuracy (second line). (Note: the `model1.evaluate` function also gives the value of loss, but we will ignore that here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss1, val_acc1 = model1.evaluate(our_val_images, our_val_labels)\n",
    "print('Validation accuracy:', val_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Other Networks (Models)\n",
    "Over 80% accuracy is pretty fascinating! If you think about it, this network (without a hidden layer) is a simple non-linear regression - a multinomial logistic regression to be exact. But let's try to do better. Let's add a hidden layer. In order not to create a mess we'll build a new model from scracth. Let's call this `model2`. The only difference is the addition of a hidden layer in the middle with 128 nodes (and yes, that's number is pretty much ad hoc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add (keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model2.add (keras.layers.Dense(128,activation='sigmoid'))\n",
    "model2.add (keras.layers.Dense(10,activation='softmax'))\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's run this one for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(our_train_images, our_train_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for some questions. What is the accuracy on the training set (displayed above)? And what is the accuracy on the validation set? To answer this second question, create a new code cell block below by copying and modifying the cell that gave us the validation accuracy for model 1. Be careful, not to mix up the model numbers.\n",
    "### <span style=\"color:red\">__bCourses Question 8:__</span> What is the accuracy of model2 on the training set?\n",
    "### <span style=\"color:red\">__bCourses Question 9:__</span> What is the accuracy of model2 on the validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">__bCourses Question 10:__</span> What is the reason for the difference between the the two accuracy levels? Is the difference a problem, can something be done about it? Briefly comment in free text, but please keep it short, not more than a 100 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The accuracy levels are not bad, let's see if we can improve by making the network deep. We'll have three hidden layers and add some dropouts as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "model3.add (keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model3.add (keras.layers.Dense(64,activation='sigmoid'))\n",
    "model3.add(keras.layers.Dropout(rate=0.1))\n",
    "model3.add (keras.layers.Dense(64,activation='sigmoid'))\n",
    "model3.add(keras.layers.Dropout(rate=0.1))\n",
    "model3.add (keras.layers.Dense(64,activation='sigmoid'))\n",
    "model3.add(keras.layers.Dropout(0.1))\n",
    "model3.add (keras.layers.Dense(10,activation='softmax'))\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "We'll try to run this for 40 epochs. If it's too slow, just hit the stop button on the top and retry with a lower number. If it's not taking too long, you can run it even longer, like 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(our_train_images, our_train_labels, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">__bCourses Question 11:__</span> What is the accuracy of model3 on the training set?\n",
    "### <span style=\"color:red\">__bCourses Question 12:__</span> What is the accuracy of model3 on the validation set?\n",
    "Create a new code cell to answer this second questions just as you did for model2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok that's enough for now. Of course, you are welcome to try other networks (we will not try CNN's here mostly because it would be slow, but the code is fairly simple), but time to pick one of the three models. Which one would you pick out of the three if you had use one in a real application?\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 13:__</span> Which model would you pick for prediction on an unseen data set?\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 14:__</span> Why did you make that choice?\n",
    "\n",
    "In the following cell block change the code so that it reflects your choice. **Important:** The code will not run if you leave it as `modelx` so change it to either `model1`, `model2`, or `model3`, whichever you picked in your previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=modelx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Performance\n",
    "Now that we committed to a model, we can now check it's performance on the test data. It is important that we didn't touch the test data before and it didn't influence our model choice, so whatever performance we get on it, we can expect the same on unseen data from the same distribution. The following code block evaluates the accuracy on the test data and stores the predictions for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = final_model.evaluate(mnist_test_images, mnist_test_labels)\n",
    "predicted_classes = final_model.predict_classes(mnist_test_images)\n",
    "predictions = final_model.predict(mnist_test_images)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Some more housekeeping: we separate the correct predictions and the incorrect predictions and display the numbers. These numbers should match the test accuracy above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.nonzero(predicted_classes==mnist_test_labels)[0]\n",
    "incorrect = np.nonzero(predicted_classes!=mnist_test_labels)[0]\n",
    "print(\"Correct predicted classes:\",correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\",incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We now plot the first 25 correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(0,49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title('True:'+class_names[mnist_test_labels[correct[i]]]+'\\n Pred:'+class_names[predicted_classes[correct[i]]])\n",
    "    plt.imshow(mnist_test_images[correct[i]], cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "And the first 25 incorrect predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(0,49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title('True:'+class_names[mnist_test_labels[incorrect[i]]]+'\\n Pred:'+class_names[predicted_classes[incorrect[i]]])\n",
    "    plt.imshow(mnist_test_images[incorrect[i]], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's take a look at the first incorrect prediction (index = 0). The first column shows the probability of the image being in each of the 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "print('True Class of incorrect image '+str(index)+' is '+class_names[mnist_test_labels[incorrect[index]]])\n",
    "print('Predictions:')\n",
    "for i in range(10):\n",
    "    print(\"{:06.2%}\".format(predictions[incorrect[index]][i])+': '+class_names[i]+'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "A nice way to see what categories are confused with each other is to display the \"confusion\" matrix. The code is long mostly to make the image nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,class_,title='Confusion matrix',cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function plots a confusion matrix\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(class_))\n",
    "    plt.xticks(tick_marks, class_, rotation=90)\n",
    "    plt.yticks(tick_marks, class_)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(confusion_matrix(mnist_test_labels, predicted_classes), class_names)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which image category does the model perform the worst on? In other words which image category is recognized in the lowest proportion? (Hint: All rows add up to 1000, so you don't have to wrry about calculating percentages)? Which category is it confused with the most?\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 15:__</span> Which category does the model recognize the least?\n",
    "### <span style=\"color:red\">__bCourses Question 16:__</span> Which category is the above confused with the most?\n",
    "\n",
    "Now let's say you don't mind if these two are confused, it's not a big deal and you just merge the two categories. How much is the accuracy of our current model if you merge these two categories? (Hint: you can calculate this manually just by looking at the confusion matrix numbers, no need for more code).\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 17:__</span> What is the accuracy of our current model on the test data if we merge the above two categories?\n",
    "\n",
    "(Note: If we were really going to merge, it would be advisable to retrain the model with the merged categories. And it would have been better to do this before touching the test data)\n",
    "\n",
    "One last thing we'll do is take a look at the images that are model does the worst on (really horribly). The code below just creates a new list with the performance numbers on the incorrectly classified images and displays these numbers for the 3 worst (classified by something else with close to 100% probability).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_list=[]\n",
    "for i in incorrect:\n",
    "    incorrect_list.append({'index':i,\n",
    "                        'pred_class':predicted_classes[i],\n",
    "                        'true_class':mnist_test_labels[i],\n",
    "                        'pred_prob_top':predictions[i][predicted_classes[i]],\n",
    "                        'pred_prob_true':predictions[i][mnist_test_labels[i]]\n",
    "                       })     \n",
    "incorrect_list.sort(key=lambda x: x['pred_prob_top'], reverse= True)  \n",
    "incorrect_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now display the 25 worst images. Why don't you try to classify these with your own eyes? Or even better ask someone else if somebody is around. Take a screenshot of the image grid and put a label on each (one of the 10 of our labels of course). And please don't cheat, you could easily look up the correct labels, but what's the fun in that (how well you classify here is obviously not part of the grade).\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 18:__</span> Upload the image grid to bCourses after manually classifying the images (use your eyes only). Upload as an image and draw/write the labels on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.subplots_adjust(hspace=0.5,wspace=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title('What is this?\\n \\n ')\n",
    "    plt.imshow(mnist_test_images[incorrect_list[i]['index']], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now let's display the predicted and true labels. And for the fun part: how did you do?\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 19:__</span> Out of the 25, how many times did you get the True label?\n",
    "### <span style=\"color:red\">__bCourses Question 20:__</span> Out of the 25, how many times did you get the Predicted label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.subplots_adjust(hspace=0.5,wspace=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title('True:'+class_names[incorrect_list[i]['true_class']]+\n",
    "              \"({:03.0%})\".format(incorrect_list[i]['pred_prob_true'])+'\\n Pred:'+\n",
    "              class_names[incorrect_list[i]['pred_class']]+\n",
    "              \"({:03.0%})\".format(incorrect_list[i]['pred_prob_top']))\n",
    "    plt.imshow(mnist_test_images[incorrect_list[i]['index']], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "That's it, we're done! One more **important** step. Please download this file as an .ipynb notebook and also as a .pdf (as a backup). To download go to the Menu and File -> Download As.\n",
    "\n",
    "Name the files as lastname_firstname.ipynb and lastname_firstname.pdf\n",
    "\n",
    "### <span style=\"color:red\">__bCourses Question 21:__</span> Upload the lastname_firstname.ipynb file\n",
    "### <span style=\"color:red\">__bCourses Question 22:__</span> Upload the lastname_firstname.pdf file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
